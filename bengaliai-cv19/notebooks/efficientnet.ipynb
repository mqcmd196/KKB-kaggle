{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"efficientnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vGJGsJfsggSr","colab_type":"code","outputId":"a987d2cc-a54c-48bf-88e9-8174d9657094","executionInfo":{"status":"ok","timestamp":1583245485816,"user_tz":-540,"elapsed":1285,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbnPaT46hSIeZHLbF8a6Unh3owb_ynaem8JYEh=s64","userId":"01726864658215807628"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U67CYVMTg7tE","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kVlikIK7wiug","colab_type":"code","outputId":"1b991087-7174-41b7-8433-082746b39ce9","executionInfo":{"status":"ok","timestamp":1583245492305,"user_tz":-540,"elapsed":5493,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbnPaT46hSIeZHLbF8a6Unh3owb_ynaem8JYEh=s64","userId":"01726864658215807628"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!pip install efficientnet_pytorch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"913nAgC-ZLbV","colab_type":"code","outputId":"43e8c01f-6d5a-46ef-b888-91af040702f9","executionInfo":{"status":"ok","timestamp":1583246934006,"user_tz":-540,"elapsed":1440139,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbnPaT46hSIeZHLbF8a6Unh3owb_ynaem8JYEh=s64","userId":"01726864658215807628"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","# from tqdm.auto import tqdm\n","import copy\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","import torchvision.models as models\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","# from torchsummary import summary\n","import gc\n","from efficientnet_pytorch import EfficientNet\n","\n","\n","dataset_dir = '../dataset'\n","#dataset_dir = '/kaggle/input/bengaliai-cv19'\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')\n","\n","# 前処理を関数にまとめた\n","def resize(X, out_height=64, out_width=64):\n","    print('Resizing raw image... / 前処理実行中…')\n","    # resized = {} # 前処理された画像が格納されるリスト\n","    resized = np.zeros((len(X), out_height * out_width))\n","\n","    for i in range(len(X)):\n","        image = X.iloc[[i]].values.reshape(HEIGHT, WIDTH)\n","        _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","        contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","        left = 1000\n","        right = -1\n","        top = 1000\n","        bottom = -1\n","\n","        for cnt in contours:\n","            x,y,w,h = cv2.boundingRect(cnt)\n","            left = min(x, left)\n","            right = max(x+w, right)\n","            top = min(y, top)\n","            bottom = max(y+h, bottom)\n","\n","        roi = image[top:bottom, left:right]\n","        resized_roi = cv2.resize(roi, (out_height, out_width),interpolation=cv2.INTER_AREA)\n","        #resized_roi = cv2.cvtColor(resized_roi, cv2.COLOR_GRAY2RGB) # efficientのinputになるため３次元化\n","        #resized_roi = np.transpose(np.array(resized_roi), (2,0,1)) -> (3,224,224)への変換をここでやるとメモリクラッシュするのでmydataset()の__get_item__()内でやる\n","        resized[i] = resized_roi.reshape(-1)\n","    return resized\n","\n","# PyTorch式のデータセットクラスを定義\n","\n","class MyDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, X, Y, transform=None):\n","        self.transform = transform\n","        self.X = X\n","        self.Y = Y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        out_data = cv2.resize(self.X[idx].reshape(64,64), (224, 224),interpolation=cv2.INTER_AREA)\n","        out_data = out_data.reshape(224, 224, 1)\n","        out_data = cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB)\n","        out_data = np.transpose(out_data, (2,0,1)) / 255 # shapeのcv2変換が終わってから /255 をやらないとエラー出る\n","        out_data = out_data.reshape(3,224,224) \n","        out_data = torch.tensor(out_data, dtype=torch.float)\n","\n","        #root_label = torch.tensor(self.Y[0][idx], dtype=torch.long)\n","        #vowel_label = torch.tensor(self.Y[1][idx], dtype=torch.long)\n","        #cons_label = torch.tensor(self.Y[2][idx], dtype=torch.long)\n","\n","        root_label = torch.tensor(np.argmax(self.Y[0][idx]), dtype=torch.long)\n","        vowel_label = torch.tensor(np.argmax(self.Y[1][idx]), dtype=torch.long)\n","        cons_label = torch.tensor(np.argmax(self.Y[2][idx]), dtype=torch.long)\n","\n","        if self.transform:\n","            out_data = self.transform(out_data)\n","\n","        return out_data, root_label, vowel_label, cons_label\n","\n","def try_gpu(e):\n","    if torch.cuda.is_available():\n","        return e.cuda()\n","    return e\n","\n","class model(nn.Module):\n","    def __init__(self):\n","        #resnet18の実装\n","        super(model, self).__init__()\n","        self.efficient_imagenet = EfficientNet.from_pretrained('efficientnet-b0')\n","        self.fc = nn.Linear(1000, 512)\n","\n","        self.head_root = nn.Linear(512, 168) # + softmax\n","        self.head_vowel = nn.Linear(512, 11) # + softmax\n","        self.head_consonant = nn.Linear(512, 7) # + softmax\n","    \n","    def forward(self, x):\n","        x = self.efficient_imagenet(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        \n","        head_root = self.head_root(x)\n","        head_vowel = self.head_vowel(x)\n","        head_consonant = self.head_consonant(x)\n","\n","        return head_root, head_vowel, head_consonant # not sure..\n","model = model()\n","#model = EfficientNet.from_pretrained('efficientnet-b0')\n","model = try_gpu(model)\n","\n","criterion1 = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(model.parameters())\n","\n","def train(model, epoch, train_loader):\n","    model.train()\n","    print(f'Epoch number {epoch}')\n","    correct_r, correct_v, correct_c = 0, 0, 0\n","    total_r, total_v, total_c = 0, 0, 0\n","\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        total_r += root_l.size(0)\n","        correct_r += (root_pred == root_l).sum()\n","        total_v += vowel_l.size(0)\n","        correct_v += (vowel_pred == vowel_l).sum()\n","        total_c += consonant_l.size(0)\n","        correct_c += (consonant_pred == consonant_l).sum()\n","        # if i % 500 == 0:\n","        #     print(\"epoch{} root {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss1.data))\n","        #     print(\"epoch{} vowel {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss2.data))\n","        #     print(\"epoch{} consonant {}/{}  loss: {}\".format(epoch, i*len(inputs), len(train_loader)*len(inputs), loss3.data))\n","    \n","    print(\"root Accuracy {}/{} {:.2f}%\".format(correct_r, total_r, 100.0*correct_r/total_r))\n","    print(\"vowel Accuracy {}/{} {:.2f}%\".format(correct_v, total_v, 100.0*correct_v/total_v))\n","    print(\"consonant Accuracy {}/{} {:.2f}%\".format(correct_c, total_c, 100.0*correct_c/total_c))\n","\n","\n","def test(model, test_loader):\n","    model.eval()\n","    correct_r, correct_v, correct_c = 0, 0, 0\n","    total_r, total_v, total_c = 0, 0, 0\n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        total_r += root_l.size(0)\n","        correct_r += (root_pred == root_l).sum()\n","        total_v += vowel_l.size(0)\n","        correct_v += (vowel_pred == vowel_l).sum()\n","        total_c += consonant_l.size(0)\n","        correct_c += (consonant_pred == consonant_l).sum()\n","\n","# 訓練ループ / Training Loop\n","\n","val_perc = 0.2  # validation set の割合（クロスバリデーション）\n","epochs = 1 #4\n","\n","#training loop\n","for parq_i in range(4):\n","    print('=============================')\n","    print(f'Parquet {parq_i} の訓練を開始')\n","\n","    train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n","\n","    HEIGHT = 137\n","    WIDTH = 236\n","\n","    X_train = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n","\n","    #X_train_resized = resize(X_train).T / 255.0   # 値を0~1におさめる\n","    X_train_resized = resize(X_train).astype(np.uint8) # astype(np.uint8)をしてあげることで後で cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB) が実行できるようになる\n","    print(\"X_train_resized.shape\", X_train_resized.shape)\n","\n","    # メモリ節約\n","    del X_train\n","\n","    # PyTorchのデータセットクラスを作る前に、ラベルの情報も整備\n","    # 1-of-K符号化とか、One Hot Encodingとか呼ばれる方法でラベルをつくる\n","\n","    # 注：　PyTorchでは、ラベルはOne Hotじゃなくて良いことが判明したので、結局 MyDataset で元のラベルに戻している\n","\n","    Y_train_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n","    Y_train_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n","    Y_train_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n","\n","    Y_train = [Y_train_root, Y_train_vowel, Y_train_cons]\n","\n","    trainval_dataset = MyDataset(X_train_resized, Y_train)\n","\n","    n_samples = len(trainval_dataset)\n","\n","    train_size = int(len(trainval_dataset)*(1.0 - val_perc))\n","    val_size = n_samples - train_size\n","    print(f'train size: {train_size}, validation size: {val_size}')\n","\n","    train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n","\n","    train_loader = DataLoader(dataset=trainval_dataset,\n","                        batch_size=32, shuffle=True, num_workers=4)\n","    val_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=0)\n","\n","    for i in range(1,epochs+1):\n","        train(model, i, train_loader)\n","        test(model, val_loader)\n","\n","    # メモリ節約\n","    del train_df_with_img\n","    del train_dataset\n","    del trainval_dataset\n","    del train_loader\n","    del X_train_resized\n","    gc.collect()\n","\n","# 提出ファイルの準備\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test_resized = resize(df_test_img).astype(np.uint8)\n","    X_test_resized = np.array([cv2.resize(X_test.reshape(64,64), (224, 224),interpolation=cv2.INTER_AREA) for X_test in X_test_resized])\n","    X_test_resized = np.array([X_test.reshape(224,224,1) for X_test in X_test_resized])\n","    X_test_resized = np.array([cv2.cvtColor(X_test, cv2.COLOR_GRAY2RGB) for X_test in X_test_resized])\n","    X_test_resized = np.array([np.transpose(X_test, (2,0,1)) for X_test in X_test_resized])\n","    X_test_resized = X_test_resized / 255\n","    X_test_resized = X_test_resized.reshape(-1, 3, 224, 224)\n","\n","    test_inputs = torch.tensor(X_test_resized, dtype=torch.float)\n","    test_inputs = Variable(test_inputs)\n","    test_inputs = try_gpu(test_inputs)\n","\n","    del X_test_resized\n","    gc.collect()\n","    \n","# テストデータをいっぺんに入れるとメモリが足りないので変更！\n","#     root_o, vowel_o, consonant_o = model(test_inputs)\n","#     root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","#     if torch.cuda.is_available():\n","#         root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","#\n","#     root_pred, vowel_pred, consonant_pred = root_pred.numpy(), vowel_pred.numpy(), consonant_pred.numpy()\n","#\n","#     for k, id in enumerate(df_test_img.index.values):\n","#         row_id.append(id+'_consonant_diacritic')\n","#         target.append(consonant_pred[k])\n","#         row_id.append(id+'_grapheme_root')\n","#         target.append(root_pred[k])\n","#         row_id.append(id+'_vowel_diacritic')\n","#         target.append(vowel_pred[k])\n","\n","    for k, id in enumerate(df_test_img.index.values):\n","        data = test_inputs[k].reshape(1, 3, 224, 224)\n","        root_o, vowel_o, consonant_o = model(data)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        if torch.cuda.is_available():\n","            root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","\n","        root_pred, vowel_pred, consonant_pred = root_pred.item(), vowel_pred.item(), consonant_pred.item()\n","        \n","        row_id.append(id+'_consonant_diacritic')\n","        target.append(consonant_pred)\n","        row_id.append(id+'_grapheme_root')\n","        target.append(root_pred)\n","        row_id.append(id+'_vowel_diacritic')\n","        target.append(vowel_pred)\n","    \n","    del df_test_img\n","    gc.collect()\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","df_sample.to_csv('submission.csv',index=False)\n","df_sample.head(36)\n","# 23:25 実行　→　24:50"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n","=============================\n","Parquet 0 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","X_train_resized.shape (50210, 4096)\n","train size: 40168, validation size: 10042\n","Epoch number 1\n","root Accuracy 33066/50210 65.86%\n","vowel Accuracy 44378/50210 88.38%\n","consonant Accuracy 45380/50210 90.38%\n","=============================\n","Parquet 1 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","X_train_resized.shape (50210, 4096)\n","train size: 40168, validation size: 10042\n","Epoch number 1\n","root Accuracy 41089/50210 81.83%\n","vowel Accuracy 47193/50210 93.99%\n","consonant Accuracy 47464/50210 94.53%\n","=============================\n","Parquet 2 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","X_train_resized.shape (50210, 4096)\n","train size: 40168, validation size: 10042\n","Epoch number 1\n","root Accuracy 42442/50210 84.53%\n","vowel Accuracy 47648/50210 94.90%\n","consonant Accuracy 47807/50210 95.21%\n","=============================\n","Parquet 3 の訓練を開始\n","Resizing raw image... / 前処理実行中…\n","X_train_resized.shape (50210, 4096)\n","train size: 40168, validation size: 10042\n","Epoch number 1\n","root Accuracy 43199/50210 86.04%\n","vowel Accuracy 47926/50210 95.45%\n","consonant Accuracy 48199/50210 95.99%\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n","Resizing raw image... / 前処理実行中…\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test_0_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test_0_grapheme_root</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test_0_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test_1_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test_1_grapheme_root</td>\n","      <td>93</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Test_1_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Test_2_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Test_2_grapheme_root</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Test_2_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Test_3_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Test_3_grapheme_root</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Test_3_vowel_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Test_4_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Test_4_grapheme_root</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Test_4_vowel_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Test_5_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Test_5_grapheme_root</td>\n","      <td>115</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Test_5_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Test_6_consonant_diacritic</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Test_6_grapheme_root</td>\n","      <td>147</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Test_6_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Test_7_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Test_7_grapheme_root</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Test_7_vowel_diacritic</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Test_8_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Test_8_grapheme_root</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Test_8_vowel_diacritic</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Test_9_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Test_9_grapheme_root</td>\n","      <td>133</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Test_9_vowel_diacritic</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Test_10_consonant_diacritic</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Test_10_grapheme_root</td>\n","      <td>148</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Test_10_vowel_diacritic</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Test_11_consonant_diacritic</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Test_11_grapheme_root</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Test_11_vowel_diacritic</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         row_id  target\n","0    Test_0_consonant_diacritic       0\n","1          Test_0_grapheme_root       3\n","2        Test_0_vowel_diacritic       0\n","3    Test_1_consonant_diacritic       0\n","4          Test_1_grapheme_root      93\n","5        Test_1_vowel_diacritic       2\n","6    Test_2_consonant_diacritic       0\n","7          Test_2_grapheme_root      19\n","8        Test_2_vowel_diacritic       0\n","9    Test_3_consonant_diacritic       0\n","10         Test_3_grapheme_root     115\n","11       Test_3_vowel_diacritic       0\n","12   Test_4_consonant_diacritic       0\n","13         Test_4_grapheme_root      55\n","14       Test_4_vowel_diacritic       4\n","15   Test_5_consonant_diacritic       0\n","16         Test_5_grapheme_root     115\n","17       Test_5_vowel_diacritic       2\n","18   Test_6_consonant_diacritic       5\n","19         Test_6_grapheme_root     147\n","20       Test_6_vowel_diacritic       9\n","21   Test_7_consonant_diacritic       0\n","22         Test_7_grapheme_root     137\n","23       Test_7_vowel_diacritic       7\n","24   Test_8_consonant_diacritic       0\n","25         Test_8_grapheme_root     119\n","26       Test_8_vowel_diacritic       9\n","27   Test_9_consonant_diacritic       0\n","28         Test_9_grapheme_root     133\n","29       Test_9_vowel_diacritic      10\n","30  Test_10_consonant_diacritic       4\n","31        Test_10_grapheme_root     148\n","32      Test_10_vowel_diacritic       1\n","33  Test_11_consonant_diacritic       0\n","34        Test_11_grapheme_root      21\n","35      Test_11_vowel_diacritic       2"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"92zJ9m2FwAnz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"cc362667-903b-4514-aaa0-6fcc26f3f289","executionInfo":{"status":"ok","timestamp":1583241723316,"user_tz":-540,"elapsed":2001,"user":{"displayName":"정범준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbnPaT46hSIeZHLbF8a6Unh3owb_ynaem8JYEh=s64","userId":"01726864658215807628"}}},"source":["!ps aux"],"execution_count":5,"outputs":[{"output_type":"stream","text":["USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n","root           1  0.0  0.0  39192  1512 ?        Ss   12:28   0:00 /bin/bash -e \n","root           9  0.0  0.1 685204 38984 ?        Sl   12:28   0:03 /tools/node/b\n","root          19  0.1  0.3 479204 81284 ?        Sl   12:28   0:05 /usr/bin/pyth\n","root         134  0.0  0.0  35888  1312 ?        Ss   12:28   0:00 tail -n +0 -F\n","root         183  0.0  0.0  18376   304 ?        S    12:31   0:00 /bin/bash --n\n","root         184  0.0  0.0 2173148 2268 ?        Sl   12:31   0:00 /opt/google/d\n","root         185  0.0  0.0  11596   280 ?        S    12:31   0:00 grep --color=\n","root         282  0.8  0.2 2421620 61992 ?       Sl   12:32   0:24 /opt/google/d\n","root         293  0.0  0.0      0     0 ?        Z    12:32   0:00 [fusermount] \n","root         327  0.0  0.0  18376   256 ?        S    12:32   0:00 bash -c tail \n","root         328  0.0  0.0   4568    64 ?        S    12:32   0:00 tail -n +0 -F\n","root         329  0.0  0.0  11464    92 ?        S    12:32   0:00 grep --line-b\n","root         719  6.7 79.3 38185800 21234072 ?   Ssl  12:50   2:07 /usr/bin/pyth\n","root        1175  0.0  0.0  59032  6408 ?        R    13:22   0:00 ps aux\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nv50wqXDbWid","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}