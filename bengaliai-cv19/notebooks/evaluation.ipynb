{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vGJGsJfsggSr","colab_type":"code","outputId":"6e96eca2-3ca0-4d2e-d0ac-970bd296386c","executionInfo":{"status":"ok","timestamp":1583897288181,"user_tz":-540,"elapsed":1711,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","%cd gdrive/My\\ Drive/KKB-kaggle/bengaliai-cv19/notebooks"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","/content/gdrive/My Drive/KKB-kaggle/bengaliai-cv19/notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U67CYVMTg7tE","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNVEBroeewc4","colab_type":"code","outputId":"24e0f43c-b352-4418-ed33-7a314f0e4000","executionInfo":{"status":"ok","timestamp":1583897292763,"user_tz":-540,"elapsed":6277,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["!pip install efficientnet_pytorch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.6.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TqMWjaRU2KU4","colab_type":"code","colab":{}},"source":["## 諸々の import\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import recall_score\n","import cv2\n","# from tqdm.auto import tqdm\n","import copy\n","import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms, utils\n","import torchvision.models as models\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torchvision\n","import PIL\n","# from torchsummary import summary\n","import gc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbsZSbkg9SrB","colab_type":"code","colab":{}},"source":["## Parameters\n","\n","# resize後のサイズ\n","HEIGHT = 64\n","WIDTH = 64\n","\n","# 画像を3次元にするかどうか（EfficientNetなどを使うときはTrue）\n","enable_3d = True\n","\n","# True なら Cross Validation を実施する\n","# Kaggle に提出するデータを作るときは False にしてください\n","do_validation = False\n","\n","# True なら submission.csv を生成する\n","create_submission = False\n","\n","val_perc = 0.2  # validation set の割合（クロスバリデーション）\n","\n","#epochs number\n","epochs = 30\n","\n","#初期値として、保存した重みを使う時はこれをTrueに\n","load_flag = True\n","\n","#Kaggleで提出するときはTrueにする\n","kaggle_flag = False\n","\n","#loadするファイルへのパス\n","if kaggle_flag:\n","    model_path = '/kaggle/input/model_load/resnet18_epoch1_2020-03-09_14-58-43.pth'\n","else:\n","    model_path = '../trained_models/resnet18_epoch32_2020-03-09_17-18-32.pth'\n","\n","if kaggle_flag:\n","    dataset_dir = '/kaggle/input/bengaliai-cv19'\n","    model_dir = '/kaggle/input/trained_models'\n","else:\n","    dataset_dir = '../dataset'\n","    model_dir = '../trained_models'\n","\n","train_df = pd.read_csv(dataset_dir + '/train.csv')\n","test_df = pd.read_csv(dataset_dir + '/test.csv')\n","class_map_df = pd.read_csv(dataset_dir + '/class_map.csv')\n","sample_sub_df = pd.read_csv(dataset_dir + '/sample_submission.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tvn9ZIpO-kz6","colab_type":"code","colab":{}},"source":["def save_ensemble(ensemble,dir):\n","    import pickle\n","    with open(dir+'/ensemble.pickle', 'wb') as f:\n","        pickle.dump(ensemble, f)\n","\n","def load_ensemble(dir):\n","    import pickle\n","    with open(dir+'/ensemble.pickle', 'rb') as f:\n","        ensemble = pickle.load(f)\n","    return ensemble"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RU66nFHqgj7K","colab_type":"code","outputId":"2463ecc7-7af3-4898-fc48-8a9976bda1aa","executionInfo":{"status":"ok","timestamp":1583898258700,"user_tz":-540,"elapsed":1419,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#モデルの設定\n","\n","from preprocess import *\n","from save_load import *\n","import model.CNN as CNN\n","import model.efficientnet as efficientnet\n","import model.resnet18 as resnet18\n","import model.resnet34 as resnet34\n","import model.resnet50 as resnet50\n","import model.resnet101 as resnet101\n","import model.resnet152 as resnet152\n","\n","#今までに作ったensembleを使う場合\n","ensemble = load_ensemble(model_dir)\n","\n","#追加するmodelの定義\n","model1 = resnet18.model()\n","optim1 = optim.Adam(model1.parameters())\n","model2 = efficientnet.model()\n","\n","#今までの分に加えて新しいものも定義\n","name_list = [\"resnet18\",\"efficientnet81\"]\n","\n","add_ensemble = [\n","    {\n","        'model': model1,\n","        'file': 'resnet18_epoch65_2020-03-10_14-34-52.pth'\n","    },\n","    {\n","        'model': model2,\n","        'file': 'efficientnet_81epoch.pth'\n","    }\n","]\n","\n","for i in range(len(add_ensemble)):\n","    ensemble = ensemble.append(add_ensemble[i])\n","\n","#modelの重みのload(古いsave()で保存している場合はload_weight(model,model_path)を、新しいsave()で保存している場合はload_model(model,optim,model_path)))を\n","model1,optim1,epoch1= load_model(model1,optim1,model_dir+'/'+ensemble[0][\"file\"])\n","model1 = try_gpu(model1)\n","ensemble[0][\"model\"]= model1\n","model2= load_weight(model2,model_dir+'/'+ensemble[1][\"file\"])\n","model2 = try_gpu(model2)\n","ensemble[1][\"model\"] = model2\n","\n","\n","# for M in ensemble としていないのは、ensembleに\"代入\"をしたいからです\n","# 参考：　https://ja.stackoverflow.com/q/31916\n","for i in range(len(ensemble)):\n","    ensemble[i][\"name\"] = name_list[i]\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n","loaded from ../trained_models/efficientnet_81epoch.pth\n","loaded from ../trained_models/resnet18_epoch65_2020-03-10_14-34-52.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h7G-i0XLtsbY","colab_type":"code","colab":{}},"source":["## train関数、test関数\n","\n","def train(model, epoch, train_loader):\n","    model.train()\n","    \n","    size = len(train_loader.dataset)\n","    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    index = 0\n","\n","    for data in train_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        optimizer.zero_grad()\n","        root_o, vowel_o, consonant_o = model(inputs)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        loss1 = criterion1(root_o, root_l)\n","        loss2 = criterion1(vowel_o, vowel_l)\n","        loss3 = criterion1(consonant_o, consonant_l)\n","        (loss1+loss2+loss3).backward()\n","        optimizer.step()\n","        for i in range(inputs.size(0)):\n","            pred_r[index] = root_pred[i]\n","            pred_v[index] = vowel_pred[i]\n","            pred_c[index] = consonant_pred[i]\n","            true_r[index] = root_l[i]\n","            true_v[index] = vowel_l[i]\n","            true_c[index] = consonant_l[i]\n","            index += 1\n","    recall_r = recall_score(true_r, pred_r, average='macro')\n","    recall_v = recall_score(true_v, pred_v, average='macro')\n","    recall_c = recall_score(true_c, pred_c, average='macro')\n","    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n","\n","    print(f'Root Recall(train): {recall_r:.5f}')\n","    print(f'Vowel Recall(train): {recall_v:.5f}')\n","    print(f'Consonant Recall(train): {recall_c:.5f}')\n","    print(f'Score(train): {final_score:.5f}')\n","   \n","\n","def test(model, test_loader):\n","    model.eval()\n","\n","    size = len(test_loader.dataset)\n","    pred_r, pred_v, pred_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    true_r, true_v, true_c = np.zeros(size), np.zeros(size), np.zeros(size)\n","    index = 0\n","    \n","    for data in test_loader:\n","        inputs, root_l, vowel_l, consonant_l = data\n","        inputs, root_l, vowel_l, consonant_l = Variable(inputs), Variable(root_l), Variable(vowel_l), Variable(consonant_l)\n","        inputs, root_l, vowel_l, consonant_l = try_gpu(inputs), try_gpu(root_l), try_gpu(vowel_l), try_gpu(consonant_l)\n","        \n","        root_o, vowel_o, consonant_o = model(inputs) \n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        for i in range(inputs.size(0)):\n","            pred_r[index] = root_pred[i]\n","            pred_v[index] = vowel_pred[i]\n","            pred_c[index] = consonant_pred[i]\n","            true_r[index] = root_l[i]\n","            true_v[index] = vowel_l[i]\n","            true_c[index] = consonant_l[i]\n","            index += 1\n","\n","    recall_r = recall_score(true_r, pred_r, average='macro')\n","    recall_v = recall_score(true_v, pred_v, average='macro')\n","    recall_c = recall_score(true_c, pred_c, average='macro')\n","    final_score = (2.*recall_r + recall_v + recall_c) / 4.\n","\n","    print(f'Root Recall(test): {recall_r:.5f}')\n","    print(f'Vowel Recall(test): {recall_v:.5f}')\n","    print(f'Consonant Recall(test): {recall_c:.5f}')\n","    print(f'Score(test): {final_score:.5f}')\n","    return true_r,pred_r,true_v,pred_v,true_c,pred_c\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wZ0lQFJ3Ajz","colab_type":"code","outputId":"fff4fd45-8382-475c-a8f8-4e13a7cf27e3","executionInfo":{"status":"ok","timestamp":1583900323821,"user_tz":-540,"elapsed":393127,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":244}},"source":["## データの読み込み\n","\n","X_all = np.empty((0, HEIGHT*WIDTH))\n","Y_root_all = np.empty((0, 168))\n","Y_vowel_all = np.empty((0, 11))\n","Y_cons_all = np.empty((0, 7))\n","\n","for parq_i in range(4):\n","    print(f'Parquet {parq_i} を読み込み中')\n","    train_df_with_img = pd.merge(pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)\n","    \n","    X = train_df_with_img.drop(columns=['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'])\n","    X_resized = resize(X, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8) # astype(np.uint8)をしてあげることで後で cv2.cvtColor(out_data, cv2.COLOR_GRAY2RGB) が実行できるようになる\n","    \n","    Y_root = pd.get_dummies(train_df_with_img['grapheme_root']).values\n","    Y_vowel = pd.get_dummies(train_df_with_img['vowel_diacritic']).values\n","    Y_cons = pd.get_dummies(train_df_with_img['consonant_diacritic']).values\n","\n","    X_all = np.append(X_all, X_resized, axis=0)\n","    Y_root_all = np.append(Y_root_all, Y_root, axis=0)\n","    Y_vowel_all = np.append(Y_vowel_all, Y_vowel, axis=0)\n","    Y_cons_all = np.append(Y_cons_all, Y_cons, axis=0)\n","\n","    del X\n","    del X_resized\n","    del Y_root\n","    del Y_vowel \n","    del Y_cons \n","    gc.collect()\n","\n","print(X_all.shape)\n","print(Y_root_all.shape)\n","print(Y_vowel_all.shape)\n","print(Y_cons_all.shape)\n","\n","Y_all = [Y_root_all, Y_vowel_all, Y_cons_all]\n","\n","trainval_dataset = MyDataset(X_all, Y_all, enable_3d=enable_3d, H=HEIGHT, W=WIDTH)\n","\n","del X_all\n","del Y_root_all\n","del Y_vowel_all\n","del Y_cons_all\n","del Y_all\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Parquet 0 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 1 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 2 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","Parquet 3 を読み込み中\n","Resizing raw image... / 前処理実行中…\n","(200840, 4096)\n","(200840, 168)\n","(200840, 11)\n","(200840, 7)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"ee2x8byvB8eW","colab_type":"code","outputId":"07400996-04a6-4074-a22d-8aed11746a3a","executionInfo":{"status":"ok","timestamp":1583900323831,"user_tz":-540,"elapsed":392286,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["## data_loaderの作成\n","\n","if do_validation:\n","    n_samples = len(trainval_dataset)\n","    train_size = int(len(trainval_dataset)*(1.0 - val_perc))\n","    val_size = n_samples - train_size\n","    print(f'train size: {train_size}, validation size: {val_size}')\n","\n","    subset, val_dataset = torch.utils.data.random_split(trainval_dataset, [train_size, val_size])\n","\n","    if enable_3d:\n","        train_dataset = TransformDataset(subset, transform=transforms.RandomChoice(\n","            [transform_none, transform_crop224, transform_rotate, transform_noise]\n","        ))\n","\n","    else:\n","        train_dataset = TransformDataset(subset, transform=transforms.RandomChoice(\n","            [transform_none, transform_crop64, transform_rotate, transform_noise]\n","        ))\n","\n","    del trainval_dataset\n","    del subset\n","    gc.collect()\n","\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False, num_workers=4)\n","    val_loader = DataLoader(dataset=val_dataset, batch_size=32, num_workers=0)\n","\n","    # メモリ節約\n","    del train_dataset\n","    del val_dataset\n","    gc.collect()\n","\n","else:\n","    n_samples = len(trainval_dataset)\n","    print(f'train size: {n_samples}')\n","\n","    if enable_3d:\n","        trainval_dataset.transform = transforms.RandomChoice(\n","            [transform_none, transform_crop224, transform_rotate, transform_noise]\n","        )\n","    \n","    else:\n","        trainval_dataset.transform = transforms.RandomChoice(\n","            [transform_none, transform_crop64, transform_rotate, transform_noise]\n","        )\n","\n","    train_loader = DataLoader(dataset=trainval_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","    # メモリ節約\n","    del trainval_dataset\n","    gc.collect()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["==========================\n","Starting training.\n","train size: 200840\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"clFpsmVBpr_h","colab_type":"code","colab":{}},"source":["def model_compare(ensemble,data_loader):\n","    N = len(ensemble)\n","    for i in range(N):\n","        true_r,pred_r,true_v,pred_v,true_c,pred_c = test(ensemble[i][\"model\"],data_loader)\n","        ensemble[i][\"correct_r\"] = true_r==pred_r\n","        ensemble[i][\"correct_v\"] = true_v==pred_v\n","        ensemble[i][\"correct_c\"] = true_c==pred_c\n","    return ensemble\n","\n","def make_df(ensemble):\n","    N = len(ensemble)\n","    #dfの作成\n","    df = pd.DataFrame()\n","    for i in range(N):\n","        df[ensemble[i][\"name\"]+\"_r\"]=ensemble[i][\"correct_r\"]\n","        df[ensemble[i][\"name\"]+\"_v\"]=ensemble[i][\"correct_v\"]\n","        df[ensemble[i][\"name\"]+\"_c\"]=ensemble[i][\"correct_c\"]\n","    return df\n","\n","def make_table(df,dir):\n","    N = len(ensemble)\n","    for i in range(N-1):\n","        for j in range(i+1,N):\n","            df1 = pd.crosstab(df[ensemble[i][\"name\"]+\"_r\"],df[ensemble[j][\"name\"]+\"_r\"],margins=True)\n","            df2 = pd.crosstab(df[ensemble[i][\"name\"]+\"_v\"],df[ensemble[j][\"name\"]+\"_v\"],margins=True)\n","            df3 = pd.crosstab(df[ensemble[i][\"name\"]+\"_c\"],df[ensemble[j][\"name\"]+\"_c\"],margins=True)\n","            print(df1)\n","            print()\n","            print(df2)\n","            print()\n","            print(df3)\n","            #dfの保存\n","            df1.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_r.csv\")\n","            df2.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_v.csv\")\n","            df3.to_csv(dir+'/'+ensemble[i][\"name\"]+\"-\"+ensemble[j][\"name\"]+\"_c.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWN2hnO2rwyd","colab_type":"code","outputId":"bd2290f0-f3dd-4c88-962d-d078048dcdd9","executionInfo":{"status":"ok","timestamp":1583901046459,"user_tz":-540,"elapsed":1112421,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":157}},"source":["ensemble = model_compare(ensemble,train_loader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Root Recall(test): 0.98845\n","Vowel Recall(test): 0.99405\n","Consonant Recall(test): 0.99510\n","Score(test): 0.99151\n","Root Recall(test): 0.99921\n","Vowel Recall(test): 0.99883\n","Consonant Recall(test): 0.99904\n","Score(test): 0.99907\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nrv43Zy6xfJE","colab_type":"code","outputId":"171cee34-f83b-4515-956d-c03e1e7874b7","executionInfo":{"status":"ok","timestamp":1583903267111,"user_tz":-540,"elapsed":1846,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["df = make_df(ensemble)\n","make_table(df,model_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["efficientnet_r  False    True     All\n","resnet18_r                           \n","False              11    1872    1883\n","True              133  198824  198957\n","All               144  200696  200840\n","\n","efficientnet_v  False    True     All\n","resnet18_v                           \n","False               2     994     996\n","True              221  199623  199844\n","All               223  200617  200840\n","\n","efficientnet_c  False    True     All\n","resnet18_c                           \n","False               8     701     709\n","True               92  200039  200131\n","All               100  200740  200840\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TPJjkftV_NnY","colab_type":"code","colab":{}},"source":["save_ensemble(ensemble,model_dir)\n","ensemble1 = load_ensemble(model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qd08GBYAxgX","colab_type":"code","outputId":"e4c35b54-6795-415d-8c96-d9988a1afc43","executionInfo":{"status":"ok","timestamp":1583903661232,"user_tz":-540,"elapsed":1398,"user":{"displayName":"中島大介","photoUrl":"","userId":"17866004412819307846"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["df1 = make_df(ensemble1)\n","make_table(df1,model_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["efficientnet_r  False    True     All\n","resnet18_r                           \n","False              11    1872    1883\n","True              133  198824  198957\n","All               144  200696  200840\n","\n","efficientnet_v  False    True     All\n","resnet18_v                           \n","False               2     994     996\n","True              221  199623  199844\n","All               223  200617  200840\n","\n","efficientnet_c  False    True     All\n","resnet18_c                           \n","False               8     701     709\n","True               92  200039  200131\n","All               100  200740  200840\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wMIW8MM2_yfF","colab":{}},"source":["## 提出ファイルの作成\n","\n","target=[]\n","row_id=[] # row_id place holder\n","\n","for parq_i in range(4):\n","    df_test_img = pd.read_parquet(dataset_dir + f'/test_image_data_{parq_i}.parquet')\n","    # df_test_img = pd.read_parquet(dataset_dir + f'/train_image_data_{parq_i}.parquet') # Error Check!\n","    df_test_img.set_index('image_id', inplace=True)\n","\n","    X_test_resized = resize(df_test_img, out_height=HEIGHT, out_width=WIDTH).astype(np.uint8)\n","\n","    for k, id in enumerate(df_test_img.index.values):\n","        X = X_test_resized[k]\n","\n","        if enable_3d:\n","            X = cv2.resize(X.reshape(HEIGHT, WIDTH), (224, 224),interpolation=cv2.INTER_AREA)\n","            X = X.reshape(224, 224, 1)\n","            X = cv2.cvtColor(X, cv2.COLOR_GRAY2RGB)\n","            X = np.transpose(X, (2,0,1)) / 255.0\n","            X = X.reshape(1, 3, 224, 224) \n","        \n","        else:\n","            X = X.reshape(1, 1, HEIGHT, WIDTH) / 255.0\n","\n","        test_input = torch.tensor(X, dtype=torch.float)\n","        test_input = Variable(test_input)\n","        test_input = try_gpu(test_input)\n","        \n","        model.eval()\n","        root_o, vowel_o, consonant_o = model(test_input)\n","        root_pred, vowel_pred, consonant_pred = torch.max(root_o.data,1)[1], torch.max(vowel_o.data,1)[1], torch.max(consonant_o.data,1)[1]\n","        if torch.cuda.is_available():\n","            root_pred, vowel_pred, consonant_pred = root_pred.to(torch.device(\"cpu\")), vowel_pred.to(torch.device(\"cpu\")), consonant_pred.to(torch.device(\"cpu\"))\n","\n","        root_pred, vowel_pred, consonant_pred = root_pred.item(), vowel_pred.item(), consonant_pred.item()\n","        \n","        row_id.append(id+'_consonant_diacritic')\n","        target.append(consonant_pred)\n","        row_id.append(id+'_grapheme_root')\n","        target.append(root_pred)\n","        row_id.append(id+'_vowel_diacritic')\n","        target.append(vowel_pred)\n","    \n","    del df_test_img\n","    del X_test_resized\n","    gc.collect()\n","\n","\n","df_sample = pd.DataFrame(\n","    {\n","        'row_id': row_id,\n","        'target':target\n","    },\n","    columns = ['row_id','target'] \n",")\n","\n","if create_submission:\n","    df_sample.to_csv('submission.csv',index=False)\n","\n","df_sample.head(36)"],"execution_count":0,"outputs":[]}]}